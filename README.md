# ASGCN Replication and Extension Project (COMP8240)

This repository contains the original work and new data artifacts for a project replicating and extending the paper **"Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks" (ASGCN)** by Zhang et al. (2019).

> **Note:**  
> This repository is **not a fork** and does **not contain the original model code**.  
> It only includes the new scripts, data, and results created for this project.

**Link to Original ASGCN Repository:** [https://github.com/GeneZC/ASGCN](https://github.com/GeneZC/ASGCN)

---

## Project Structure

This repository is organized to highlight the new work created for this project.

### `/data_preparation/`
Contains all original Python scripts written to create the new datasets. This includes:

- `scrape_reddit.py`: Scrapes comments from specified Reddit threads using the PRAW API.  
- `clean_data.py`: Cleans raw text, fixes encoding errors, and removes noise.  
- `split_sentences.py`: Splits multi-sentence comments into single sentences using **spaCy**.  
- `extract_aspects.py`: Extracts aspect term candidates (noun chunks) from the sentences.  
- `calculate_iaa.py`: Calculates the **Cohenâ€™s Kappa** score between two annotator files.
- `find_disagreements.py`: Finds Disagreements Between the Two Annotators' CSV files.
- `convert_to_raw.py`: Converts the final adjudicated CSV annotations into the 3-line `.raw` format required by the ASGCN model and splits them into **train** and **test** files.
- `convert_mams_to_raw.py`: Converts the XML formatted data from MAMS dataset (new EXISTING dataset) to 3-line .raw format for ASGCN

### `/new_data_sourcing/`
Contains the intermediate files from the data creation pipeline.

- `raw_data/`: The original raw CSV files scraped from Reddit.
- `all_comments_cleaned.csv`: File generated by `clean_data.py`, containing cleaned comments.
- `all_comments_sentences.csv`: File generated by `split_sentences.py`, containing comments that have been split into single sentences.
- `annotation_tasks.csv`: File generated by `extract_aspects.py`, containing possible aspect terms for the sentences.
- `annotator_1.csv` / `annotator_2.csv`: Files annotated independently by two annotators.  
- `disagreements_to_fix.csv`: File generated by `calculate_iaa.py` showing annotation conflicts.  
- `agreements.csv`: File containing all non-conflicting (agreed) annotations.  

### `/datasets/`
Contains the final, model-ready datasets.

- `reddit/`: Includes `reddit_train.raw`, `reddit_test.raw`, and the corresponding `.graph` and `.tree` files.  
- `mams/`: Includes the converted `MAMS_train.raw`, `MAMS_test.raw`, and their corresponding `.graph` and `.tree` files.

### `/logs/`
Contains `.txt` output logs from experimental runs, including **Accuracy** and **F1-scores** for both the replication and new dataset experiments.

### `requirements.txt`
Lists all Python dependencies required to run both the original ASGCN code and the new data preparation scripts.

---

## How to Reproduce This Project

To replicate or extend the experiments, combine the **original ASGCN code** with the **new files** from this repository.

### 1. Clone the Original ASGCN Repository
```bash
git clone https://github.com/GeneZC/ASGCN.git
```

### 2. Clone this project Repository
```bash
git clone https://github.com/48491942/ASGCN-Replication-and-Extension-Project-COMP8240.git
```

### 3. Set up the Environment
We will create a new Conda environment and install all packages from this project's `requirements.txt` file.  
```bash
conda create -n asgcn_project python=3.8
conda activate asgcn_project
```

Install all required packages by providing the folder path in which the `requirements.txt` file is located.
``` bash
pip install -r /path/to/requirements.txt
```

### 4. Navigate to the **ASGCN** folder you just cloned from the original respository
```bash
cd ASGCN
```

### 5. Add new project files
Copy the files from **this** repository into the **ASGCN** folder:   
- Copy the `datasets/reddit/` and `datasets/mams/` folders into the `ASGCN/datasets/` folder.
- Copy the `logs/` folder into the `ASGCN/` root directory.
- Modify the `ASGCN/data_utils.py` to include the new 'reddit' and 'mams' datasets in the `fname` dictionary.
- Modify the `ASGCN/dependency_graph.py` and `ASGCN/dependency_tree.py` to process the new `.raw` files. (This step is already complete, as the `.graph` and `.tree` files are already provided).


### 6. Run the experiments
You can now run the training scripts as described in the original repository.

Example: Run ASGCN-DG on the new Reddit dataset

```bash
python train.py --model_name asgcn --dataset reddit
```
Example: Run ASGCN-DT on the new MAMS dataset

```bash
python train.py --model_name astcn --dataset mams
```
